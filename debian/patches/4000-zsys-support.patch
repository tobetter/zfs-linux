Description: Support zsys systems
 Zsys is an enhanced and structured dataset layout for ZFS.
 .
 It enables advanced use cases by differentiating system,
 user data and persistent partitions to allow only partial
 permanent or temporary rollback without destroying intermediate
 snapshots.
Author: Jean-Baptiste Lallement <jean.baptiste@ubuntu.com>
        Didier Roche <didrocks@ubuntu.com>
Last-Update: 2019-06-06
Index: zfs-linux-0.8.2/contrib/initramfs/scripts/zfs.in
===================================================================
--- zfs-linux-0.8.2.orig/contrib/initramfs/scripts/zfs.in
+++ zfs-linux-0.8.2/contrib/initramfs/scripts/zfs.in
@@ -482,16 +482,13 @@ clone_snap()
 	local snap="$1"
 	local destfs="$2"
 	local mountpoint="$3"
+	local additional_parameters="$4"
 
 	[ "$quiet" != "y" ] && zfs_log_begin_msg "Cloning '$snap' to '$destfs'"
 
 	# Clone the snapshot into a dataset we can boot from
-	# + We don't want this filesystem to be automatically mounted, we
-	#   want control over this here and nowhere else.
-	# + We don't need any mountpoint set for the same reason.
-	# We use the 'org.zol:mountpoint' property to remember the mountpoint.
-	ZFS_CMD="${ZFS} clone -o canmount=noauto -o mountpoint=none"
-	ZFS_CMD="${ZFS_CMD} -o org.zol:mountpoint=${mountpoint}"
+	ZFS_CMD="${ZFS} clone"
+	ZFS_CMD="${ZFS_CMD} -o canmount=noauto -o mountpoint=${mountpoint} ${additional_parameters}"
 	ZFS_CMD="${ZFS_CMD} $snap $destfs"
 	ZFS_STDERR="$(${ZFS_CMD} 2>&1)"
 	ZFS_ERROR="$?"
@@ -603,6 +600,15 @@ setup_snapshot_booting()
 	snapname="${snap##*@}"
 	ZFS_BOOTFS="${rootfs}_${snapname}"
 
+	# Detect if we are on a zsys system, which will generates an unique UUID
+	# and override ZFS_BOOTFS
+	use_zsys=$(get_fs_value "${rootfs}" com.ubuntu.zsys:bootfs)
+	if [ "$use_zsys" = "yes" ]; then
+		zsys_uid=`uid`
+		ZFS_BOOTFS="${rootfs%_*}_${zsys_uid}" # we strip old uid and add new one
+	fi
+
+	# Rollback won't have effect on zsys system
 	if ! grep -qiE '(^|[^\\](\\\\)* )(rollback)=(on|yes|1)( |$)' /proc/cmdline
 	then
 		# If the destination dataset for the clone
@@ -632,10 +638,18 @@ setup_snapshot_booting()
 			#       rpool/ROOT/debian/boot@snap2	=> rpool/ROOT/debian_snap2/boot
 			#       rpool/ROOT/debian/usr@snap2	=> rpool/ROOT/debian_snap2/usr
 			#       rpool/ROOT/debian/var@snap2	=> rpool/ROOT/debian_snap2/var
+			#
+			# For zsys, we have stable root dataset names with uid, so:
+			#       rpool/ROOT/debian_uid1@snap2		=> rpool/ROOT/debian_uid2
+			#       rpool/ROOT/debian_uid1/boot@snap2	=> rpool/ROOT/debian_uid2/boot
+
 			subfs="${s##$rootfs}"
 			subfs="${subfs%%@$snapname}"
 
 			destfs="${rootfs}_${snapname}" # base fs.
+			if [ "${use_zsys}" = "yes" ]; then
+				destfs="${rootfs%_*}_${zsys_uid}" # we strip old uid and add new one
+			fi
 			[ -n "$subfs" ] && destfs="${destfs}$subfs" # + sub fs.
 
 			# Get the mountpoint of the filesystem, to be used
@@ -652,9 +666,33 @@ setup_snapshot_booting()
 				fi
 			fi
 
+			# On non zsys:
+			# + We don't want this filesystem to be automatically mounted, we
+			#   want control over this here and nowhere else.
+			# + We don't need any mountpoint set for the same reason.
+			# + We use the 'org.zol:mountpoint' property to remember the mountpoint.
+			# On zsys:
+			# + We don't want this filesystem to be automatically mounted, when cloned
+			#   so, we set canmount=noauto. Zsys early boot will set the current datasets
+			#   to on, alongside other system datasets switch. This enables
+			#   zpool import -a -R /altroot to mount the whole system.
+			#   The initrd script is doing zpool import -N, so we are not impacted by setting
+			#   canmount=on on secondary boot.
+			# + We thus need the real mountpoint set for this reason (as we can't set it
+			#   once the system booted, even if the mountpoint didn't change)
+			# + We set additional parameters to zsys to mark datasets we want mount manually
+			#   at boot.
+			if [ "${use_zsys}" != "yes" ]; then
+				clone_additional_parameters="-o org.zol:mountpoint=${mountpoint}"
+				mountpoint=none
+			else
+				[ "$(get_fs_value "$s" com.ubuntu.zsys:bootfs)" != "yes" ] && continue
+				clone_additional_parameters="-o com.ubuntu.zsys:bootfs=yes"
+			fi
+
 			# Clone the snapshot into its own
 			# filesystem
-			clone_snap "$s" "${destfs}" "${mountpoint}" || \
+			clone_snap "$s" "${destfs}" "${mountpoint}" "${clone_additional_parameters}" || \
 			    retval=$((retval + 1))
 		fi
 	done
@@ -910,6 +948,8 @@ mountroot()
 		# Booting from a snapshot?
 		# Will overwrite the ZFS_BOOTFS variable like so:
 		#   rpool/ROOT/debian@snap2 => rpool/ROOT/debian_snap2
+		#   or
+		#   rpool/ROOT/debian@snap2 => rpool/ROOT/debian_<uid> if selected system is a zsys one
 		echo "${ZFS_BOOTFS}" | grep -q '@' && \
 		    setup_snapshot_booting "${ZFS_BOOTFS}"
 	fi
@@ -947,8 +987,16 @@ mountroot()
 	# Go through the complete list (recursively) of all filesystems below
 	# the real root dataset
 	filesystems=$("${ZFS}" list -oname -tfilesystem -H -r "${ZFS_BOOTFS}")
+
+	# If the root filesystem is a zsys one, we select the datasets to mount
+	# at boot.
+	# Some datasets under ROOT/ can be mounted on top of persistent datasets
+	# that are hosted elsewhere in the pool. Those are thus only mounted at
+	# early boot.
+	use_zsys=$(get_fs_value "${ZFS_BOOTFS}" com.ubuntu.zsys:bootfs)
 	for fs in $filesystems $ZFS_INITRD_ADDITIONAL_DATASETS
 	do
+		[ "$use_zsys" = "yes" -a "$(get_fs_value "$fs" com.ubuntu.zsys:bootfs)" != "yes" ] && continue
 		mount_fs "$fs"
 	done
 
@@ -987,3 +1035,8 @@ mountroot()
 		[ "$quiet" != "y" ] && zfs_log_end_msg
 	fi
 }
+
+uid()
+{
+	dd if=/dev/urandom of=/dev/stdout bs=1 count=100 2>/dev/null | tr -dc 'a-z0-9' | cut -c-6
+}
Index: zfs-linux-0.8.2/etc/systemd/system-generators/zfs-mount-generator.in
===================================================================
--- zfs-linux-0.8.2.orig/etc/systemd/system-generators/zfs-mount-generator.in
+++ zfs-linux-0.8.2/etc/systemd/system-generators/zfs-mount-generator.in
@@ -28,6 +28,8 @@ FSLIST="@sysconfdir@/zfs/zfs-list.cache"
 
 [ -d "${FSLIST}" ] || exit 0
 
+OLD_IFS=$IFS
+
 do_fail() {
   printf 'zfs-mount-generator: %s\n' "$*" > /dev/kmsg
   exit 1
@@ -247,6 +249,55 @@ EOF
   ln -s "../${mountfile}" "${req_dir}"
 }
 
+ZSYS="@sbindir@/zsys"
+ZFS="@sbindir@/zfs"
+ZPOOL="@sbindir@/zpool"
+initial_pools=""
+fs_pools=""
+all_pools=""
+on_exit() {
+    # Restore initial zpool import state
+    IFS=$OLD_IFS
+    for pool in ${all_pools}; do
+        if echo "${initial_pools}" | grep -wq "${pool}"; then
+            continue
+        fi
+        if echo "${fs_pools}" | grep -wq "${pool}"; then
+            continue
+        fi
+        zpool export "${pool}"
+    done
+}
+
+# TODO: we should move that in its own script, and use a systemd service as a fallback.
+# We need to condition this on current vs previous dataset (across the whole system), so
+# in /boot.
+# We will also recall the zedlet directly and regenerate the files if any changes were
+# made.
+initzsys() {
+  if [ ! -x "${ZSYS}" ]; then
+    return
+  fi
+  trap on_exit EXIT INT QUIT ABRT PIPE TERM
+
+  # import and list pools for zsys
+  initial_pools="$(${ZPOOL} list | awk '{if (NR>1) print $1}')"
+  ${ZPOOL} import -f -a -N -o cachefile=none 2>/dev/null
+  all_pools="$(zpool list | awk '{if (NR>1) print $1}')"
+  ${ZSYS} boot prepare
+
+  PROPS="name,mountpoint,canmount,atime,relatime,devices,exec,readonly"
+  PROPS="${PROPS},setuid,nbmand"
+
+  for cachefile in "${FSLIST}/"* ; do
+    pool=`basename $cachefile`
+    fs_pools="${fs_pools} ${pool}"
+    ${ZFS} list -H -t filesystem -o $PROPS -r "${pool}" > "${cachefile}"
+  done
+}
+
+initzsys
+
 # Feed each line into process_line
 for cachefile in "${FSLIST}/"* ; do
   while read -r fs ; do
