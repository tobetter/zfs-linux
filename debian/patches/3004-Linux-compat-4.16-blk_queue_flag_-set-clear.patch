From d6bb22171b6e4e8b16a8243b8cd63f571f11c4ff Mon Sep 17 00:00:00 2001
From: Brian Behlendorf <behlendorf1@llnl.gov>
Date: Thu, 12 Apr 2018 19:46:14 -0700
Subject: [PATCH] Linux compat 4.16: blk_queue_flag_{set,clear}
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 8bit

The HAVE_BLK_QUEUE_WRITE_CACHE_GPL_ONLY case was overlooked in
the original 10f88c5c commit because blk_queue_write_cache()
was available for the in-kernel builds.

Update the blk_queue_flag_{set,clear} wrappers to call the locked
versions to avoid confusion.  This is safe for all existing callers.

The blk_queue_set_write_cache() function has been updated to use
these wrappers.  This means setting/clearing both QUEUE_FLAG_WC
and QUEUE_FLAG_FUA is no longer atomic but this only done early
in zvol_alloc() prior to any requests so there is no issue.

Reviewed-by: Tony Hutter <hutter2@llnl.gov>
Reviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>
Reviewed-by: Kash Pande <kash@tripleback.net>
Signed-off-by: Brian Behlendorf <behlendorf1@llnl.gov>
Closes #7428
Closes #7431
---
 include/linux/blkdev_compat.h | 14 ++++++--------
 1 file changed, 6 insertions(+), 8 deletions(-)

diff --git a/include/linux/blkdev_compat.h b/include/linux/blkdev_compat.h
index d7af1d89d..f99980ab3 100644
--- a/include/linux/blkdev_compat.h
+++ b/include/linux/blkdev_compat.h
@@ -41,7 +41,7 @@ typedef unsigned __bitwise__ fmode_t;
 static inline void
 blk_queue_flag_set(unsigned int flag, struct request_queue *q)
 {
-	queue_flag_set_unlocked(flag, q);
+	queue_flag_set(flag, q);
 }
 #endif
 
@@ -49,7 +49,7 @@ blk_queue_flag_set(unsigned int flag, struct request_queue *q)
 static inline void
 blk_queue_flag_clear(unsigned int flag, struct request_queue *q)
 {
-	queue_flag_clear_unlocked(flag, q);
+	queue_flag_clear(flag, q);
 }
 #endif
 
@@ -72,16 +72,14 @@ static inline void
 blk_queue_set_write_cache(struct request_queue *q, bool wc, bool fua)
 {
 #if defined(HAVE_BLK_QUEUE_WRITE_CACHE_GPL_ONLY)
-	spin_lock_irq(q->queue_lock);
 	if (wc)
-		queue_flag_set(QUEUE_FLAG_WC, q);
+		blk_queue_flag_set(QUEUE_FLAG_WC, q);
 	else
-		queue_flag_clear(QUEUE_FLAG_WC, q);
+		blk_queue_flag_clear(QUEUE_FLAG_WC, q);
 	if (fua)
-		queue_flag_set(QUEUE_FLAG_FUA, q);
+		blk_queue_flag_set(QUEUE_FLAG_FUA, q);
 	else
-		queue_flag_clear(QUEUE_FLAG_FUA, q);
-	spin_unlock_irq(q->queue_lock);
+		blk_queue_flag_clear(QUEUE_FLAG_FUA, q);
 #elif defined(HAVE_BLK_QUEUE_WRITE_CACHE)
 	blk_queue_write_cache(q, wc, fua);
 #elif defined(HAVE_BLK_QUEUE_FLUSH_GPL_ONLY)
-- 
2.17.0

